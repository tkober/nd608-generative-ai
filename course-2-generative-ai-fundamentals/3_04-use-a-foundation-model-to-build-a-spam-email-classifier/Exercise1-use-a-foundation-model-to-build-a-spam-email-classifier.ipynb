{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Use a foundation model to build a spam email classifier\n",
    "\n",
    "A foundation model serves as a fundamental building block for potentially endless applications. One application we will explore in this exercise is the development of a spam email classifier using only the prompt. By leveraging the capabilities of a foundation model, this project aims to accurately identify and filter out unwanted and potentially harmful emails, enhancing user experience and security.\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. Identify and gather relevant data\n",
    "2. Build and evaluate the spam email classifier\n",
    "3. Build an improved classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Identify and gather relevant data\n",
    "\n",
    "To train and test the spam email classifier, you will need a dataset of emails that are labeled as spam or not spam. It is important to identify and gather a suitable dataset that represents a wide range of spam and non-spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets==3.2.0\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting huggingface-hub==0.27.1\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from datasets==3.2.0) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from datasets==3.2.0) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from datasets==3.2.0) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from datasets==3.2.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from datasets==3.2.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from datasets==3.2.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from datasets==3.2.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from datasets==3.2.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from datasets==3.2.0) (0.70.16)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from datasets==3.2.0) (3.11.13)\n",
      "Requirement already satisfied: packaging in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from datasets==3.2.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from datasets==3.2.0) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from huggingface-hub==0.27.1) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from aiohttp->datasets==3.2.0) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets==3.2.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets==3.2.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets==3.2.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets==3.2.0) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from pandas->datasets==3.2.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from pandas->datasets==3.2.0) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from pandas->datasets==3.2.0) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/thorsten/code/udacity/nd608-generative-ai/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.17.0)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, huggingface-hub, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.12.0\n",
      "    Uninstalling fsspec-2024.12.0:\n",
      "      Successfully uninstalled fsspec-2024.12.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.29.1\n",
      "    Uninstalling huggingface-hub-0.29.1:\n",
      "      Successfully uninstalled huggingface-hub-0.29.1\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.3.2\n",
      "    Uninstalling datasets-3.3.2:\n",
      "      Successfully uninstalled datasets-3.3.2\n",
      "Successfully installed datasets-3.2.0 fsspec-2024.9.0 huggingface-hub-0.27.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade datasets==3.2.0 huggingface-hub==0.27.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df9f32f09574b59aa4aa2b3c6250f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457e7811b1454ca6a9dd1d0484ce478c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/359k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab7f2995f9843979ce674350025b55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=0, sms=Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "label=0, sms=Ok lar... Joking wif u oni...\n",
      "\n",
      "label=1, sms=Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find a spam dataset at https://huggingface.co/datasets and load it using the datasets library\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"sms_spam\", split=[\"train\"])[0]\n",
    "\n",
    "for entry in dataset.select(range(3)):\n",
    "    sms = entry[\"sms\"]\n",
    "    label = entry[\"label\"]\n",
    "    print(f\"label={label}, sms={sms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those labels could be easier to read. Let's create some functions to convert numerical ids to labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=NOT SPAM, sms=Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "label=NOT SPAM, sms=Ok lar... Joking wif u oni...\n",
      "\n",
      "label=SPAM, sms=Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convenient dictionaries to convert between labels and ids\n",
    "id2label = {0: \"NOT SPAM\", 1: \"SPAM\"}\n",
    "label2id = {\"NOT SPAM\": 0, \"SPAM\": 1}\n",
    "\n",
    "for entry in dataset.select(range(3)):\n",
    "    sms = entry[\"sms\"]\n",
    "    label_id = entry[\"label\"]\n",
    "    print(f\"label={id2label[label_id]}, sms={sms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build and evaluate the spam email classifier\n",
    "\n",
    "Using the foundation model and the prepared dataset, you can create a spam email classifier.\n",
    "\n",
    "Let's write a prompt that will ask the model to classify 15 message as either \"spam\" or \"not spam\". For easier parsing, we can ask the LLM to respond in JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (label=NOT SPAM) -> Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "1 (label=NOT SPAM) -> Ok lar... Joking wif u oni...\n",
      "\n",
      "2 (label=SPAM) -> Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's start with this helper function that will help us format sms messages\n",
    "# for the LLM.\n",
    "def get_sms_messages_string(dataset, item_numbers, include_labels=False):\n",
    "    sms_messages_string = \"\"\n",
    "    for item_number, entry in zip(item_numbers, dataset.select(item_numbers)):\n",
    "        sms = entry[\"sms\"]\n",
    "        label_id = entry[\"label\"]\n",
    "\n",
    "        if include_labels:\n",
    "            sms_messages_string += (\n",
    "                f\"{item_number} (label={id2label[label_id]}) -> {sms}\\n\"\n",
    "            )\n",
    "        else:\n",
    "            sms_messages_string += f\"{item_number} -> {sms}\\n\"\n",
    "\n",
    "    return sms_messages_string\n",
    "\n",
    "\n",
    "print(get_sms_messages_string(dataset, range(3), include_labels=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a bit of code that will produce your prompt. Your prompt should include a few SMS message to be labelled as well as instructions for the LLM.\n",
    "\n",
    "Some LLMs will also format the output for you as JSON if you ask them, e.g. \"Respond in JSON format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with your code\n",
    "\n",
    "# Get a few messages and format them as a string\n",
    "sms_messages_string = get_sms_messages_string(dataset, range(7, 15))\n",
    "\n",
    "# Construct a query to send to the LLM including the sms messages.\n",
    "# Ask it to respond in JSON format.\n",
    "query = <MASK>\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with your LLMs response\n",
    "\n",
    "response = <MASK>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the accuracy of your classifier by comparing your responses to the labels in the dataset\n",
    "\n",
    "\n",
    "def get_accuracy(response, dataset, original_indices):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for entry_number, prediction in response.items():\n",
    "        if int(entry_number) not in original_indices:\n",
    "            continue\n",
    "\n",
    "        label_id = dataset[int(entry_number)][\"label\"]\n",
    "        label = id2label[label_id]\n",
    "\n",
    "        # If the prediction from the LLM matches the label in the dataset\n",
    "        # we increment the number of correct predictions.\n",
    "        # (Since LLMs do not always produce the same output, we use the\n",
    "        # lower case version of the strings for comparison)\n",
    "        if prediction.lower() == label.lower():\n",
    "            correct += 1\n",
    "\n",
    "        # increment the total number of predictions\n",
    "        total += 1\n",
    "\n",
    "    try:\n",
    "        accuracy = correct / total\n",
    "    except ZeroDivisionError:\n",
    "        print(\"No matching results found!\")\n",
    "        return\n",
    "\n",
    "    return round(accuracy, 2)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {get_accuracy(response, dataset, range(7, 15))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not bad! (Assuming you used an LLM capable of handling this task)\n",
    "\n",
    "Surely it won't be correct for every example we throw at it, but it's a great start, especially for not giving it any examples or training data.\n",
    "\n",
    "We can see that the model is able to distinguish between spam and non-spam messages with a high degree of accuracy. This is a great example of how a foundation model can be used to build a spam email classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build an improved classifier?\n",
    "\n",
    "If you provide the LLM with some examples for how to complete a task, it will sometimes improve its performance. Let's try that out here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with your code that constructs a query to send to the LLM\n",
    "\n",
    "# Get a few labelled messages and format them as a string\n",
    "sms_messages_string_w_labels = get_sms_messages_string(\n",
    "    dataset, range(54, 60), include_labels=True\n",
    ")\n",
    "\n",
    "# Get a few unlabelled messages and format them as a string\n",
    "sms_messages_string_no_labels = get_sms_messages_string(dataset, range(7, 15))\n",
    "\n",
    "\n",
    "# Construct a query to send to the LLM including the labelled messages\n",
    "# as well as the unlabelled messages. Ask it to respond in JSON format\n",
    "query = <MASK>\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paste in your response from the LLM below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with your LLMs response\n",
    "\n",
    "response = <MASK>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the accuracy now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the accuracy?\n",
    "\n",
    "print(f\"Accuracy: {get_accuracy(response, dataset, range(7,15)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any misclassified items, let's view them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the messages that were misclassified, if you have any\n",
    "\n",
    "\n",
    "def print_misclassified_messages(response, dataset):\n",
    "    for entry_number, prediction in response.items():\n",
    "        label_id = dataset[int(entry_number)][\"label\"]\n",
    "        label = id2label[label_id]\n",
    "\n",
    "        if prediction.lower() != label.lower():\n",
    "            sms = dataset[int(entry_number)][\"sms\"]\n",
    "            print(\"---\")\n",
    "            print(f\"Message: {sms}\")\n",
    "            print(f\"Label: {label}\")\n",
    "            print(f\"Prediction: {prediction}\")\n",
    "\n",
    "\n",
    "print_misclassified_messages(response, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting (if there were any mistakes). What do you think is going on?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
