{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you are tasked with creating an application that aggregates and summarizes restaurant reviews. Users will provide the name of a restaurant and the type of cuisine, and the application will generate a summary of the most prevalent sentiments found in online reviews for that specific restaurant and cuisine type.\n",
    "\n",
    "**Challenge** \n",
    "\n",
    "Develop a prompt template that guides the LLM to generate a concise, sentiment-focused summary based on user inputs: the restaurant name and the type of cuisine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understand the User Inputs**\n",
    "\n",
    "Identify the essential user inputs for this task. In this scenario, you need:\n",
    "- Restaurant Name\n",
    "- Cuisine Type\n",
    "- Can you think of others to make your prompt more specific or flexible? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables to store the user inputs\n",
    "restaurant_name = 'Hashimoto Saarbrücken'\n",
    "cuisine_type = 'Japanese'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Craft the Prompt**\n",
    "\n",
    "Compose a clear, concise instruction that will direct the LLM to generate a sentiment-focused summary for the specified restaurant and cuisine.\n",
    " - The prompt should be specific enough to guide the LLM towards the desired output \n",
    " - But also flexible enough to handle a range of restaurants and cuisines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'Restaurant: {restaurant_name}\\n'\n",
    "prompt += f'Cuisine: {cuisine_type}\\n\\n'\n",
    "prompt += 'Find available reviews and sumnarize these in a concise manner.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the Prompt Template**\n",
    "\n",
    "Design a template that integrates the user inputs into the LLM prompt.\n",
    "Use brackets {} to denote where the user inputs should be placed. This makes the template dynamic, allowing for different restaurant names and cuisine types to be inserted into the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant: Hashimoto Saarbrücken\n",
      "Cuisine: Japanese\n",
      "\n",
      "Find available reviews and sumnarize these in a concise manner.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = prompt\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, call the OpenAI GPT-3.5 API with your prompt and see how the model responds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Generated review:\n",
      "An error occurred: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"VOCAREUM_OPENAI_API_KEY\")\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "\n",
    "\n",
    "def generate_restaurant_review(prompt_template):\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages=[\n",
    "          {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a restaurant critic. You are writing about reviews of restaurants. \"\n",
    "          },\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt_template\n",
    "          }\n",
    "          ],\n",
    "        temperature=1,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "        # The response is a JSON object containing more information than the generated review. We want to return only the message content\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Generating the response from the model\n",
    "review_summary = generate_restaurant_review(prompt_template)\n",
    "\n",
    "# Printing the output. \n",
    "print(\"Generated review:\")\n",
    "print(review_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
